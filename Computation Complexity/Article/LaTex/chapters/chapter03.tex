\section{Анализ работы}

\subsection{Реализация алгоритма 1.5-приближения}

См. проект на \href{\GitHubLink}{\textit{GitHub}} (ограниченный доступ).

Для реализации структуры данных для \textit{поиска наименьшего общего предка} и \textit{сжатия соцветий} использованы методы,
описанные в работах Berkman и Vishkin \cite{berkman1993recursive},
а также улучшения, предложенные Fischer и Heun \cite{fischer2006theoretical}.
Код был написан Владимиром Колмогоровым \cite{kolmogorov_lca}.

\subsection{Результаты тестирования алгоритма}

Представим результаты работы в виде таблиц с отметками про количество графов $N$, на которых проводилось усреднение,
среднее время работы в миллисекундах $T$,
среднее значение приближения $S = \frac{\sum\limits_{i=1}^{N}W(H'_i)}{\sum\limits_{i=1}^{N}W(H^*(G_i))}$ и
максимальное отклонение от ожидания (в нижнюю сторону) $B = 1.5 - \min\limits_{i}\left(\frac{W(H')}{W(H^*(G))} \right)$.

\subsection*{Малые графы}
Для малых графов (\(n \leq 10\)) алгоритм демонстрирует хорошее время работы и точность приближения.
Результаты тестов приведены в таблице ниже.

\begin{table}[ht!]
    \centering
    \[
        \begin{array}{|c|c|c|c|}
            \hline
            \text{Кол-во графов } N & \text{Ср. время } T & \text{Ср. приближение } S & \text{Макс. отклонение } B \\
            \hline
            100000                  & 0.002               & 1.326                     & 0.500                      \\
            \hline
        \end{array}
    \]
    \caption{Результаты тестирования на малых случайных графах (\(n \in [5, 10]\))}
    \label{tab:small_graphs}
\end{table}

Оценить результат работы на малых графах трудно,
так как существует малое количество различных комбинаций взаимного расположения и отношения весов.
Потому алгоритм показывает результаты сильно лучше, чем полученная теоретическая оценка.

\subsection*{Случайные графы}
Для случайных графов \(G(n, p)\) (\(n = 500, p = 0.5\)) алгоритм работает немного медленнее, но остаётся эффективным. Время работы и качество приближения приведены в таблице.

\begin{table}[ht!]
    \centering
    \[
        \begin{array}{|c|c|c|c|}
            \hline
            \text{Кол-во графов } N & \text{Ср. время } T & \text{Ср. приближение } S & \text{Макс. отклонение } B \\
            \hline
            500                     & 0.139               & 1.433                     & 0.110                      \\
            \hline
        \end{array}
    \]
    \caption{Результаты тестирования на случайных графах \(G(n, p)\) (\(n = 5000, p = 0.5\))}
    \label{tab:gnp_graphs}
\end{table}

\subsection*{Реальные данные}
Попытаемся воспроизвести реальные данные.
Можно рассматривать, например, дорожную сеть, где $w$ близка к пограничной по условию метричночти (неравенство треугольника выполняется на грани).

Алгоритм показал удовлетворительные результаты. Среднее время работы и точность приближения приведены в таблице ниже.

\begin{table}[ht!]
    \centering
    \[
        \begin{array}{|c|c|c|c|}
            \hline
            \text{Кол-во графов } N & \text{Ср. время } T & \text{Ср. приближение } S & \text{Макс. отклонение } B \\
            \hline
            500                     & 0.134               & 1.472                     & 0.055                      \\
            \hline
        \end{array}
    \]
    \caption{Результаты тестирования \(G(n, p)\) (\(n = 500, p = 0.5\)) с критическим $w$}
    \label{tab:real_data}
\end{table}

Веса ребер сильно приближены друг к другу, потому мы получаем результат хуже, чем на случайных графах,
выбирая не самые оптимальные вершины и последующем поиске минимального паросочетания.

\subsection*{Крупные графы}
Для крупных графов (\(n \geq 5000\)) алгоритм демонстрирует значительное увеличение времени работы, что логично. Результаты тестирования приведены в таблице.

\begin{table}[ht!]
    \centering
    \[
        \begin{array}{|c|c|c|c|}
            \hline
            \text{Кол-во графов } N & \text{Ср. время } T & \text{Ср. приближение } S & \text{Макс. отклонение } B \\
            \hline
            10                      & 27.355              & 1.489                     & 0.038                      \\
            \hline
        \end{array}
    \]
    \caption{Результаты тестирования на крупных графах (\(n \geq 100\))}
    \label{tab:large_graphs}
\end{table}

С ростом $N$ нивелируется эффект случайности и мы получаем асимптотически сходящийся результат работы.

\subsection{Выводы}

В силу большой асимптотической сложности алгоритма применять его на больших данных не представляется возможным локально,
так как требуются гигантсткие вычислительные мощности, но на графах умеренного размера мы получаем средний результат даже чуть лучше,
чем теоретическая оценка.

Тем не менее, предложенный алгоритм может найти эффективное применение в задачах оптимизации локальных процессов,
например эффективного расчете времени запуска студентов на экзамен или планирования маршрута для человека,
которому мнужно успеть сразу в несколько мест.
Последнюю идею уже реализовали в навигационной системе \href{https://navitel.ru/}{\textit{Navitel}},
где такая возможность даже на большом размере графа дорог предоставляется благодаря оффлайн-работе.
То есть, можно оставить большую долю вычислений в предпосчете.
