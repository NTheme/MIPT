####################
Домашнее задание 2-2
####################

Описание
========

В рамках данного задания требуется выполнить 4 задачи. Каждая задача должна быть оформлена в виде отдельного task{1,2,3,4,5}.ipynb файла и tensorboard{1,2,3,4,5}.zip файла.
В каждом файле *.ipynb должно быть:

- построение архитектуры;
- выполнен процесс обучения;
- показан пример работы модели до обучения и после;

Файл .zip должен содержать результаты эксперимента в формате tensorboard для каждой из задач:

- для каждого набора параметров свой график зависимости качества от обучения (если требуется в задаче);
- примеры работы модели в процессе обучения модели.

Для каждой задачи должны быть представлены выводы:

- какой результат ожидали;
- какой не ожидали;
- что было не ясно.

Код и эксперимент должен быть понятным внешнему читателю:

- В коде должны быть коментарии;
- Названия переменных должно быть интерпретируемые.

P.S. Рекомендуется все вычисления проводить на google colab в режиме cuda.

P.S.S. Рекомендуется использовать backup моделей при обучении на google drive.

Задачи
======

Задача 1. Распознавания именованных сущностей на основе fasttext
----------------------------------------------------------------

Построить модель расспознавания именованных сущностей на русском языке. В качестве данных использовать выборку NERUS (NER).

- В качестве векторного представления токенов использовать fasttext модель;
- В качестве модели использовать модель LSTM;
- Архитектуру LSTM можно выбрать произвольным образом;
- Весь процесс обучения должен быть визуализирован в tensorboard (метрики качества и пример предсказания)

P.S. Выборку можно взять из `github <https://github.com/natasha/nerus>`_.

P.S.S. Для экономинии памяти компютера предлагается воспользоваться сжатием модели fasttext с 300-мерного к 100-мерному (на колаб не хватит оперативки на сжатие до 100-мерного вектора, поэтому работайте сразу с 300-мерными в VEC формате). А также использовать выполнить переопределения модели fasttext в VEC модель (см. sem-17).

Задача 2. Классификация даты документа
--------------------------------------

Построить модель для классификации даты (года) публикации новостной заметки из выборки lenta.ru.

- В качестве векторного представления текста рассмотреть тематический вектор.
- В качестве классификатора использовать любой классификатор на ваш выбор.
- Проанализировать качество классификации в зависимости от добавленных модальностей.
- Провести эксперимент по добавлению регуляризаторов.
- Провести анализ классификации модальности(год рассмотреть как модальность) при помощи встроенных методов bigartm.

P.S. Выборку можно взять из sem-19. Времено не работает ссылка из семинара, используйте ссылку в `яндексе <https://disk.yandex.ru/d/bwUVH8hR1MRNrg>`_.

Задача 3. Posterior Sampling в задаче RL
----------------------------------------

Большая задача на разбор `статьи <https://arxiv.org/pdf/1306.0940.pdf>`_. Требуется решить проблемы "Задачи о заплыве" связанные с тем, что алгоритм не доходит до левого края и начинает всегда скатываться по течению.

P.S. Реализируйте метод Posterior Sampling из статьи.

P.S.S. Рекомендую посмотреть часть семинара sem-25 связаной с данной проблемой.

Задача 4. Детекция машинной генерации
----------------------------------------

Требуется построить базовый классификатор машинносгенерированных текстов. Современные методы генерации текстов позволяют генерировать тест, которые трудно отличимы от человеских текстов. В рамках данного задания предлагается реализовать простой метод детекции на базе моделей кодировщика трансформера. В качестве базовых статей предлагается использовать работы (реализовать любую из моделей классификации, указанных в данных работах):

- G.M. Gritsay, A. V. Grabovoy, A. S. Kildyakov, and Yu V. Chekhovich. Artificially generated text fragments search in academic documents. Doklady Mathematics, 2024.
- German Gritsay, Andrey Grabovoy, Alexander Kildyakov, and Yury Chekhovich. Automated text identification: Multilingual transformer-based models approach. In Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2023) co-located with the Conference of the Spanish Society for Natural Language Processing (SEPLN 2023), volume 3496 of CEUR Workshop Proceedings, CEUR-WS.org, 2023.
- German Gritsay, Andrey Grabovoy, and Yury Chekhovich. Automatic detection of machine generated texts: Need more tokens. In Ivannikov Memorial Workshop Proceedings 2022, 2022.

Выборки для обучения и тестирования предлагается использовать с соревнования SemEval 2024 (https://github.com/mbzuai-nlp/SemEval2024-task8). В рамках конкурса рассматривались 3 типа задачи: бинарной классификации (machine vs human), мультиклассовой классификации (generative model classification), детекция машинносгенерированного фрагмента в тексте. Данные задачи идут в порядке увеличения сложности, предлагается решать именно как задачу бинарной классификации, но в целом можно решать любую из представленных 3х подзадач.

P.S. при проблемах с доступами к статьям, можно написать на почту за исходниками.
