{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание 8, Адаптивные методы.\n",
    "### Deadline -  08.11.2024    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основная часть\n",
    "\n",
    "__Внимание: эта часть домашнего задания про ML, поэтому если у вас на локальном устройстве недоступна CUDA, то настоятельно рекомендуем воспользоваться google collab или же kaggle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "from typing import Callable, Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задача 1 (5 баллов).__ В данном домашнем задании мы рассмотрим обучение небольших сверточных сетей для классификации датасета CIFAR10. Так как в большинстве случаев при работе с сетками, имеющими не один, а несколько слоев, функции потерь становятся невыпуклыми, удобно использовать проксимальные методы. В нашем случае мы рассмотрим семейство адаптивных методов, таких как ```AdaGrad```, ```RMSProp```и ```Adam```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "# загружаем датасет\n",
    "cifar_train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=cifar_transform\n",
    ")\n",
    "cifar_test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=cifar_transform\n",
    ")\n",
    "# будем использовать только часть данных\n",
    "cifar_ratio = 0.5\n",
    "# делим данные train и test\n",
    "cifar_train_dataset, _ = random_split(\n",
    "    cifar_train_dataset,\n",
    "    [cifar_ratio, 1 - cifar_ratio],\n",
    "    generator=torch.Generator().manual_seed(420),\n",
    ")\n",
    "cifar_test_dataset, _ = random_split(\n",
    "    cifar_test_dataset,\n",
    "    [cifar_ratio, 1 - cifar_ratio],\n",
    "    generator=torch.Generator().manual_seed(420),\n",
    ")\n",
    "print(f\"{len(cifar_train_dataset)=}\")\n",
    "print(f\"{len(cifar_test_dataset)=}\")\n",
    "assert len(cifar_train_dataset) == 25000\n",
    "assert len(cifar_test_dataset) == 5000\n",
    "cifar_train_loader = DataLoader(\n",
    "    cifar_train_dataset, batch_size=16, shuffle=True\n",
    ")\n",
    "cifar_test_loader = DataLoader(\n",
    "    cifar_test_dataset, batch_size=256, shuffle=False\n",
    ")\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "def imshow(image):\n",
    "    image = image / 2 + 0.5  # де-нормализуем\n",
    "    np_image = image.numpy()\n",
    "    plt.imshow(np.transpose(np_image, (1, 2, 0)))\n",
    "    plt.show()\n",
    "# несколько случайных элементов\n",
    "images, labels = next(iter(cifar_train_loader))\n",
    "images, labels = images[:8], labels[:8]\n",
    "# выведем изображения\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# выведем метки\n",
    "print(\" \".join(f\"{classes[labels[j]]:5s}\" for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее уже написана модель со следующими слоями. Подробнее про них вы можете прочитать в документации torch.\n",
    "\n",
    "1. Сверточный слой 1:  ```Conv2d(in=3, out=6, kernel=5)```;\n",
    "\n",
    "2. Пулинговый слой: ```MaxPool2d(kernel=2, stride=2)```;\n",
    "\n",
    "3. Сверточный слой 2:  ```Conv2d(in=6, out=16, kernel=5)```;\n",
    "\n",
    "4. Полносвязный слой 1: ```Linear(400, 120)```;\n",
    "\n",
    "5. Полносвязный слой 2: ```Linear(120, 84)```;\n",
    "\n",
    "6. Полносвязный слой 3: ```Linear(84, 10)```.\n",
    "\n",
    "\n",
    "\n",
    "```forward``` функция:\n",
    "\n",
    "1. Свертка первым слоем -> функция активации (ReLU) -> пулинг;\n",
    "\n",
    "2. Свертка вторым слоем -> функция активации (ReLU) -> пулинг;\n",
    "\n",
    "3. Полносвязный слой 1 -> функция активации (ReLU);\n",
    "\n",
    "4. Полносвязный слой 2 -> функция активации (ReLU);\n",
    "\n",
    "5. Выход - значение на полносвязном слое 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте с помощью функции ниже, что у вашей модели 62006 обучаемых параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model, input_size):\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "            m_key = f\"{class_name}-{module_idx+1}\"\n",
    "            summary[m_key] = {\n",
    "                \"input_shape\": list(input[0].size()),\n",
    "                \"output_shape\": list(output.size()),\n",
    "                \"nb_params\": sum(p.numel() for p in module.parameters())\n",
    "            }\n",
    "        if not isinstance(module, nn.Sequential) and not isinstance(module, nn.ModuleList) and module != model:\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "    summary = {}\n",
    "    hooks = []\n",
    "    model.apply(register_hook)\n",
    "    with torch.no_grad():\n",
    "        model(torch.zeros(1, *input_size))\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "    print(line_new)\n",
    "    print(\"================================================================\")\n",
    "    total_params = 0\n",
    "    for layer in summary:\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"])\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "        print(line_new)\n",
    "    print(\"================================================================\")\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "model = CifarNet()\n",
    "print_model_summary(model, (3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__а) (0.25 балла)__ Дополните функции обучения (```train_cifar```) и подсчета метрик (```eval_cifar```). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(\n",
    "    model: nn.Module, optimizer: torch.optim.Optimizer, **loss_kwargs\n",
    ") -> None:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for inputs, labels in cifar_train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        # Обнулите градиенты\n",
    "        ...\n",
    "        # Получите выход модели\n",
    "        output = ...\n",
    "        # Подсчитайте функцию потерь\n",
    "        loss = ...\n",
    "        loss.backward(**loss_kwargs)\n",
    "        optimizer.step()\n",
    "\n",
    "def eval_cifar(model: nn.Module) -> tuple[float, float]:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs, labels in cifar_test_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Для подсчета accuracy нам понадобится найти отношение\n",
    "            # правильно предсказанных меток ко всем меткам            \n",
    "            total += ...\n",
    "            correct += ...\n",
    "            # Подсчитайте значение валидационной ошибки\n",
    "            val_loss += ...\n",
    "            \n",
    "    return val_loss, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__б) (0.25 балла)__ Реализуйте функцию логгирования результатов, полученных при обучении, заполнив пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_optimizers_cifar(\n",
    "    optimizers: list[\n",
    "        tuple[str, Callable[[Iterator[nn.Parameter]], torch.optim.Optimizer]]\n",
    "    ],\n",
    "    epochs: int = 20,\n",
    "    model_class: Callable[[], nn.Module] = CifarNet,\n",
    ") -> dict:\n",
    "    results_dict = {}\n",
    "    for name, optimizer_lambda in optimizers:\n",
    "        test_losses = []\n",
    "        accuracies = []\n",
    "        time_logs = []\n",
    "        torch.manual_seed(420)\n",
    "        model = model_class().to(DEVICE)\n",
    "        optimizer = optimizer_lambda(model.parameters())\n",
    "\n",
    "        # Начальная инициализация eval\n",
    "        loss, accuracy = ...\n",
    "        # Произведите логгирование\n",
    "        ...\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        with tqdm(range(epochs), desc=name) as loop:\n",
    "            for _ in loop:\n",
    "\n",
    "                # Обучающи режим (ОБЯЗАТЕЛЬНО сохраним граф вычислений, используя create_graph=True)\n",
    "                ...\n",
    "                # Подсчет функции потерь и accuracy\n",
    "                loss, accuracy = ...\n",
    "                # Произведите логгирование\n",
    "                ...\n",
    "                torch.cuda.synchronize()\n",
    "                \n",
    "                time_logs.append(time.time() - start_time)\n",
    "                loop.set_postfix({\"Loss\": ..., \"Accuracy\": ...})\n",
    "        results_dict[name] = {\n",
    "            \"Epoch\": list(range(epochs + 1)),\n",
    "            \"Time\": time_logs,\n",
    "            \"Test Loss\": test_losses,\n",
    "            \"Accuracy\": accuracies,\n",
    "        }\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__в) (0.75 балла)__ Перейдем к написанию оптимизационных методов. Реализуйте первый из адаптивных методов ```AdaGrad```. Для предотвращаения переобучения будем использовать $L_2$ регуляризацию весов (добавление члена $\\frac{\\lambda}{2} \\| x \\|_2^2$ к значению функции потерь).\n",
    "\n",
    "\n",
    "\n",
    "**Псевдокод алгоритма**\n",
    "\n",
    "\n",
    "\n",
    "_Инициализация:_\n",
    "\n",
    "\n",
    "\n",
    "Величина шага $\\{ \\gamma_k \\}_{k=0} > 0$, регуляризатор $\\lambda$, константа уменьшения шага $\\eta$, бегущее среднее (аккумулятор градиентов) $s_0 = 0$.\n",
    "\n",
    "\n",
    "\n",
    "$k \\hspace{-1em}$ _--ая итерация:_\n",
    "\n",
    "1. Подсчитать градиент $g_{k + 1} = \\nabla f(x_k)$\n",
    "\n",
    "2. Обновить шаг\n",
    "\n",
    "$$\\gamma_{k + 1 } = \\frac{\\gamma_k}{1 + k\\eta} $$\n",
    "\n",
    "3. Если параметр регуляризации $\\lambda$ не равен 0, добавить регуляризационный член:\n",
    "\n",
    "$$\n",
    "\n",
    "\\hat{g}_{k + 1} = g_{k + 1} + \\lambda x\n",
    "\n",
    "$$\n",
    "\n",
    "4. Обновить бегущее среднее, добавив $\\hat{g}_{k + 1}^2$\n",
    "\n",
    "$$\n",
    "\n",
    "s_{k + 1} = s_k + \\hat{g}_{k + 1}^2\n",
    "\n",
    "$$\n",
    "\n",
    "5. Сделать шаг алгоритма (для вычислительной стабильности используйте $\\varepsilon = 10^{-8}$)\n",
    "\n",
    "$$ x^{k+1} = x^k - \\gamma_{k + 1} \\frac{\\hat{g}_{k + 1}}{\\sqrt{s_{k + 1}} + \\varepsilon} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "class Adagrad(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements Adagrad algorithm.\n",
    "    It has been proposed in `Adaptive Subgradient Methods for Online Learning and Stochastic Optimization`.\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-2)\n",
    "        lr_decay (float, optional): learning rate decay (default: 0)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "    .. _Adaptive Subgradient Methods for Online Learning and Stochastic Optimization:\n",
    "        http://jmlr.org/papers/v12/duchi11a.html\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1e-2, lr_decay=0, weight_decay=0):\n",
    "        defaults = dict(lr=lr, lr_decay=lr_decay, weight_decay=weight_decay)\n",
    "        super(Adagrad, self).__init__(params, defaults)\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        \n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                \n",
    "                # Ваше решение\n",
    "                ...\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__г) (0.75 балла)__ Теперь реализуем ```RMSProp```. Основным отличием является менее аггресивное обновление бегущего среднего градиентов через использования момента $\\alpha_k$.\n",
    "\n",
    "\n",
    "\n",
    "**Псевдокод алгоритма**\n",
    "\n",
    "\n",
    "\n",
    "_Инициализация:_\n",
    "\n",
    "\n",
    "\n",
    "Величина шага $\\{ \\gamma_k \\}_{k=0} > 0$, момент $\\alpha_k > 0$, регуляризатор $\\lambda$, бегущее среднее $s_0 = 0$.\n",
    "\n",
    "\n",
    "\n",
    "$k \\hspace{-1em}$ _--ая итерация:_\n",
    "\n",
    "1. Подсчитать градиент $g_{k + 1} = \\nabla f(x_k)$\n",
    "\n",
    "2. Если параметр регуляризации $\\lambda$ не равен 0, добавить регуляризационный член:\n",
    "\n",
    "$$\n",
    "\n",
    "\\hat{g}_{k + 1} = g_{k + 1} + \\lambda x\n",
    "\n",
    "$$\n",
    "\n",
    "4. Обновить бегущее среднее\n",
    "\n",
    "$$\n",
    "\n",
    "s_{k + 1} = \\alpha_k s_k + (1 - \\alpha_k) \\hat{g}_{k + 1}^2\n",
    "\n",
    "$$\n",
    "\n",
    "5. Сделать шаг алгоритма (для вычислительной стабильности используйте $\\varepsilon = 10^{-8}$)\n",
    "\n",
    "$$ x^{k+1} = x^k - \\gamma_{k + 1} \\frac{\\hat{g}_{k + 1}}{\\sqrt{s_{k + 1}} + \\varepsilon} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements RMSprop algorithm, proposed by G. Hinton in his\n",
    "    `course <http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`\n",
    "    \n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-2)\n",
    "        alpha (float, optional): smoothing constant (default: 0.99)\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1e-2, alpha=0.99, eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, alpha=alpha, eps=eps, weight_decay=weight_decay)\n",
    "        super(RMSprop, self).__init__(params, defaults)\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        \n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                \n",
    "                # Ваше решение\n",
    "                ...\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__д) (0.75 балла)__ Перейдем к самому популярному алгоритму оптимизации ```Adam```. В нем добавляется еще один момент для обновления среднего градиентов. \n",
    "\n",
    "\n",
    "\n",
    "**Псевдокод алгоритма**\n",
    "\n",
    "\n",
    "\n",
    "_Инициализация:_\n",
    "\n",
    "\n",
    "\n",
    "Величина шага $\\{ \\gamma_k \\}_{k=0} > 0$, моменты $\\beta_, \\beta_2 > 0$, регуляризатор $\\lambda$, усредненный градиентный момент $m_0 = 0$, бегущее среднее (второй момент) $v_0 = 0$.\n",
    "\n",
    "\n",
    "\n",
    "$k \\hspace{-1em}$ _--ая итерация:_\n",
    "\n",
    "1. Подсчитать градиент $g_{k + 1} = \\nabla f(x_k)$\n",
    "\n",
    "2. Если параметр регуляризации $\\lambda$ не равен 0, добавить регуляризационный член:\n",
    "\n",
    "$$\n",
    "\n",
    "\\hat{g}_{k + 1} = g_{k + 1} + \\lambda x\n",
    "\n",
    "$$\n",
    "\n",
    "4. Обновить первый момент\n",
    "\n",
    "$$\n",
    "\n",
    "m_{k + 1} = \\beta_1 m_k + (1 - \\beta_1) \\hat{g}_k\n",
    "\n",
    "$$\n",
    "\n",
    "5. Обновить второй момент\n",
    "\n",
    "$$\n",
    "\n",
    "v_{k + 1} = \\beta_2 v_k + (1 - \\beta_2) \\hat{g}_{k + 1}^2\n",
    "\n",
    "$$\n",
    "\n",
    "6. Выполнить поправку смещения\n",
    "\n",
    "$$\n",
    "\n",
    "\\hat{m}_{k + 1} = \\frac{m_{k + 1}}{\\sqrt{1 + \\beta_1^k}} \\qquad \\hat{v}_{k + 1} = \\frac{v_{k + 1}}{\\sqrt{1 + \\beta_2^k}}   \n",
    "\n",
    "$$\n",
    "\n",
    "5. Сделать шаг алгоритма (для вычислительной стабильности используйте $\\varepsilon = 10^{-8}$)\n",
    "\n",
    "$$ x^{k+1} = x^k - \\gamma_{k + 1} \\frac{\\hat{m}_{k + 1}}{\\sqrt{\\hat{v}_{k + 1}} + \\varepsilon} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Implements Adam algorithm, proposed in the paper\n",
    "    `Adam: A Method for Stochastic Optimization` \n",
    "    by Kingma and Ba <https://arxiv.org/abs/1412.6980>`\n",
    "    \n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-2)\n",
    "        betas (tuple, optional): contains two momentums' values\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay: float = 1e-2,):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        super(Adam, self).__init__(params, defaults)\n",
    "   \n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                \n",
    "                # Ваше решение\n",
    "                ...\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__е) (0.75 балла)__ Что? Еще? Да, ведь если задуматься, то регуляризация в Адаме работает немного не так, как было изначально задумано. Так как обновленный градиент после этого используется при подсчете моментов, то при итоговом обновлении параметров мы получаем очень сложную зависимость от $\\lambda$, что выливается в большую проблему при поиске оптимальных параметров. Поэтому было предложено использовать термин *затухание весов*, убрав регуляризационный член из обновления градиента и добавив его при обновлении параметров:\n",
    "$$\n",
    "\\hat{g}_{k + 1} = g_{k + 1} \\textcolor{red}{+ \\lambda x}\n",
    "$$\n",
    "$$ x^{k+1} = x^k - \\gamma_{k + 1} \\frac{m_{k + 1}}{\\sqrt{v_{k + 1}} + \\varepsilon} \\textcolor{green}{- \\gamma_{k + 1} \\lambda x_k} $$\n",
    "Реализуйте алгоритм ```AdamW``` с затуханием весов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamW(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Implements AdamW algorithm, proposed in the paper\n",
    "    `Decoupled Weight Decay Regularization` \n",
    "    by Loschilov and Hutter <https://paperswithcode.com/paper/decoupled-weight-decay-regularization>`\n",
    "    \n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-2)\n",
    "        betas (tuple, optional): contains two momentums' values\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay: float = 1e-2,):\n",
    "        # Отметим, что в данном оптимизаторе weight_decay подразумевает не L2-регуляризацию\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        super(Adam, self).__init__(params, defaults)\n",
    "   \n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                \n",
    "                # Ваше решение\n",
    "                ...\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ж) (1.5 балла)__ Теперь пришло время обучения. Поставьте параметры методов на дефолтные значения (можно посмотреть в pytorch), изменяйте только параметр ```weight_decay``` отвечающий за регуляризацию/изменение весов (в случае AdamW). Постройте графики сходимости ошибки на обучающей и точности на валидационной выборках при ```weight_decay in [1e-1, 1e-3, 1e-4]```. Число эпох поставьте равным 15. Что можно сказать о сходимости методов? Влияет ли переосмысление ```weight_decay``` в случае Adam и AdamW?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваше решение (Code + Markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задача 1 (5 баллов).__ Сложность достижения быстрой сходимости и качественных решений во многом зависит от выбранной скорости обучения. Приложения с большим количеством агентов, каждый из которых имеет свой оптимизатор, усложняют настройку скорости обучения. Некоторые оптимизаторы, настраиваемые вручную, показывают хорошие результаты, но эти методы обычно требуют квалификации специалистов и трудоемкой работы. Поэтому в последние годы для оптимизации без изменения скорости обучения стали популярны «беспараметрические» методы адаптивной скорости обучения (_parameter-free methods_). В этой задаче мы познакомимся с основными из них.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__а) (1.5 балла)__ Первым рассмотрим метод ```COCOB``` (хыхы) (см. [статью](https://arxiv.org/pdf/1705.07795)). Он основан на схеме ставок на монету, когда на каждой итерации ставится определенная сумма денег на исход подбрасывания монеты таким образом, чтобы максимизировать общее богатство, находящееся в распоряжении. Франческо Орабона применяет ту же идею к оптимизации функции, где ставка соответствует размеру шага, сделанного вдоль оси независимой переменной. Общее богатство и результат броска монеты соответствуют\n",
    "точке оптимума функции и отрицательному субградиенту функции в точке ставки, соответственно. В каждом раунде ставится часть текущего общего богатства (точка оптимума). Стратегия ставок разработана таким образом, что общее богатство не становится отрицательным ни в одной точке, а доля поставленных денег в каждом раунде увеличивается до тех пор, пока исход броска монеты не станет постоянным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOB(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements the COCOB algorithm, which has been proposed in \n",
    "    `Training Deep Networks without Learning Rates Through Coin Betting`\n",
    "    https://arxiv.org/abs/1705.07795 .\n",
    "    \n",
    "    Args:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        alpha (float, optional): It was proposed to increase the stability in the first iterations,\n",
    "            similarly and independently to the learning rate warm-up. The number roughly denotes the\n",
    "            number of rounds of warm-up (default 100)\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, params, alpha: float = 100, eps: float = 1e-8, weight_decay: float = 0):\n",
    "        defaults = dict(weight_decay=weight_decay, lr=1.0)\n",
    "        self._alpha = alpha\n",
    "        self._eps = eps\n",
    "        super(COCOB, self).__init__(params, defaults)\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure = None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "        \n",
    "        for group in self.param_groups:\n",
    "            \n",
    "            for p in group['params']:\n",
    "                \n",
    "                # Ваше решение\n",
    "                ...\n",
    "                                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__б) (1.5 балла)__ Вторым же _paramter-free_ методом будет ```Prodigy```, недавно представленный в работе [Prodigy: An Expeditiously Adaptive Parameter-Free Learner](https://arxiv.org/pdf/2306.06101). В нем используется чуть более продвинутое решение, а именно использование адаптивного шага, как в ```AdaGrad```. Обновление также использует скользящее среднее, хотя оно более консервативно, поскольку использует $\\sqrt{\\beta_2}$ вместо $\\beta_2$. Обратите внимание, что в обновлении для $v_k$ присутствует дополнительное значение $(1 - \\beta_2)$, которое может быть опционально компенсировать с помощью поправки на смещение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import math\n",
    "class Prodigy(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Implements Adam with Prodigy step-sizes.\n",
    "    Leave LR set to 1e-1 unless you encounter instability.\n",
    "   \n",
    "    Arguments:\n",
    "        params (iterable):\n",
    "            Iterable of parameters to optimize or dicts defining parameter groups.\n",
    "        lr (float):\n",
    "            Learning rate adjustment parameter. Increases or decreases the Prodigy learning rate.\n",
    "        betas (Tuple[float, float], optional): coefficients used for computing\n",
    "            running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        beta3 (float):\n",
    "            coefficients for computing the Prodidy stepsize using running averages.\n",
    "            If set to None, uses the value of square root of beta2 (default: None).\n",
    "        eps (float):\n",
    "            Term added to the denominator outside of the root operation to improve numerical stability. (default: 1e-8).\n",
    "        weight_decay (float):\n",
    "            Weight decay, i.e. a L2 penalty (default: 0).\n",
    "        decouple (boolean):\n",
    "            Use AdamW style decoupled weight decay\n",
    "        use_bias_correction (boolean):\n",
    "            Turn on Adam's bias correction. Off by default.\n",
    "        safeguard_warmup (boolean):\n",
    "            Remove lr from the denominator of D estimate to avoid issues during warm-up stage. Off by default.\n",
    "        d0 (float):\n",
    "            Initial D estimate for D-adaptation (default 1e-6). Rarely needs changing.\n",
    "        d_coef (float):\n",
    "            Coefficient in the expression for the estimate of d (default 1.0).\n",
    "            Values such as 0.5 and 2.0 typically work as well. \n",
    "            Changing this parameter is the preferred way to tune the method.\n",
    "            \n",
    "        growth_rate (float):\n",
    "            prevent the D estimate from growing faster than this multiplicative rate.\n",
    "            Default is inf, for unrestricted. Values like 1.02 give a kind of learning\n",
    "            rate warmup effect.\n",
    "        fsdp_in_use (bool):\n",
    "            If you're using sharded parameters, this should be set to True. The optimizer\n",
    "            will attempt to auto-detect this, but if you're using an implementation other\n",
    "            than PyTorch's builtin version, the auto-detection won't work.\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=1.0,\n",
    "                 betas=(0.9, 0.999), beta3=None,\n",
    "                 eps=1e-8, weight_decay=0, decouple=True, \n",
    "                 use_bias_correction=False, safeguard_warmup=False,\n",
    "                 d0=1e-6, d_coef=1.0, growth_rate=float('inf'),\n",
    "                 fsdp_in_use=False):\n",
    "        if decouple and weight_decay > 0:\n",
    "            print(f\"Using decoupled weight decay\")\n",
    "       \n",
    "        defaults = dict(lr=lr, betas=betas, beta3=beta3,\n",
    "                        eps=eps, weight_decay=weight_decay,\n",
    "                        d=d0, d0=d0, d_max=d0,\n",
    "                        d_numerator=0.0, d_coef=d_coef,\n",
    "                        k=0, growth_rate=growth_rate,\n",
    "                        use_bias_correction=use_bias_correction,\n",
    "                        decouple=decouple, safeguard_warmup=safeguard_warmup,\n",
    "                        fsdp_in_use=fsdp_in_use)\n",
    "        self.d0 = d0\n",
    "        super().__init__(params, defaults)\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            \n",
    "            loss = closure()\n",
    "\n",
    "        # Ваше решение\n",
    "        ...\n",
    "        for group in self.param_groups:\n",
    "            \n",
    "            # Ваше решение\n",
    "            ...\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__в) (2 балла)__ Немного отклонимся от темы безпараметрических методов, и вернемся к проксимальному оператору, который возникает при использовании композита (регуляризационного члена). При этом, единственное предположение, которое делается о функции композита -- что он выпуклый. То есть в общем случае предполагать его дифференцируемость нельзя. Рассмотрим пример такого композита -- регуляризацию Tikhanov + Lasso (также известную как $L_1 + L_2$/$L_{12}$/ElasticNet). То есть задача оптимизации превращается в следующую:\n",
    "$$\n",
    "\\min F(x) \\coloneqq \\frac{1}{n}\\sum \\limits_{i = 1}^n f_i(x) + \\alpha \\| x \\|_1 + (1 - \\alpha) \\| x \\|_2^2\n",
    "$$\n",
    "Вычислите проксимальный оператор для такой функции и реализуйте метод ProxSGD (можно с моментом, можно без), проведите эксперименты для разных значений параметра $\\alpha$ (который также называют $L_1$-ratio). Например, для: 0, 0.1, 0.3, 0.6, 0.9, 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import required\n",
    "from copy import deepcopy\n",
    "class ProxSGD(Optimizer):\n",
    "    \"\"\"\n",
    "    Adaptation of  torch.optim.SGD to proximal stochastic gradient descent (optionally with momentum).\n",
    "    Nesterov momentum is based on the formula from\n",
    "    \n",
    "    `On the importance of initialization and momentum in deep learning`__.\n",
    "    Arguments:\n",
    "     params (iterable):\n",
    "            Iterable of parameters to optimize or dicts defining parameter groups.\n",
    "        lr (float):\n",
    "            Learning rate adjustment parameter. Increases or decreases the Prodigy learning rate.\n",
    "        alpha (float, optional): \n",
    "            \n",
    "            l1-ratio used in the regularizer.\n",
    "        momentum (float, optional): \n",
    "            \n",
    "            momentum factor (default: 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, params, lr=required, alpha=0.5, momentum=0.,):\n",
    "        self.alpha = alpha\n",
    "        defaults = dict(lr=lr, momentum=momentum)\n",
    "        super().__init__(params, defaults)\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                \n",
    "                loss = closure()\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                \n",
    "                # Ваше решение\n",
    "                ...\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваше решение"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
