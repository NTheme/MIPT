\section{Билет 4}

\subsection{Итерации метода тяжелого шарика и ускоренного градиентного метода
    (метода Нестерова). Интуиция: почему может быть лучше, чем градиентный спуск, как подбирать моментнумный параметр.
    Характер сходимости для гладких сильно выпуклых задач. Особенности сходимости по
    сравнению с градиентным спуском.}

\subsection*{Метод тяжелого Шарика и кота Матроскина}

\begin{algorithm}[ht]
    \caption{Метод тяжелого шарика}
    \textbf{Вход:} размер шагов $\{\gamma_k\}_{k=0}^{\infty} > 0$, моментумы $\{\tau_k\}_{k=0}^{\infty} \in [0; 1]$, стартовая точка $x_0 = x_{-1} \in \mathbb{R}^d$, количество итераций $K$.
    \begin{algorithmic}[1]
        \For{$k = 0, 1, \dots, K - 1$}
        \State Вычислить $\nabla f(x_k)$
        \State $x_{k+1} = x_k - \gamma_k \nabla f(x_k) + \tau_k (x_k - x_{k-1})$
        \EndFor
    \end{algorithmic}
    \textbf{Выход:} $x_K$
\end{algorithm}

Характер сходимости --- линейная.

\subsection*{Метод \texorpdfstring{\sout{Нейчева}}{d} Нестерова}
\begin{algorithm}[ht]
    \caption{Ускоренный градиентный метод}
    \textbf{Вход:} размер шагов $\{\gamma_k\}_{k=0}^{\infty} > 0$, моментумы $\{\tau_k\}_{k=0}^{\infty} \in [0; 1]$, стартовая точка $x_0 = y_0 \in \mathbb{R}^d$, количество итераций $K$.
    \begin{algorithmic}[1]
        \For{$k = 0, 1, \dots, K - 1$}
        \State Вычислить $\nabla f(y_k)$
        \State $x_{k+1} = y_k - \gamma_k \nabla f(y_k)$
        \State $y_{k+1} = x_{k+1} + \tau_k (x_{k+1} - x_k)$
        \EndFor
    \end{algorithmic}
    \textbf{Выход:} $x_K$
\end{algorithm}

Характер сходимости --- линейная.

\begin{note}
    Методы значительно ускоряют сходимость.
    Это достигается за счет использования информации о предыдущих шагах,
    что позволяет сделать более агрессивные шаги в направлении минимума,
    и тем самым избежать слишком медленных изменений на каждом шаге.
\end{note}


\subsection{Хор. Формулировка оценки сходимости
    ускоренного градиентного метода для гладких сильно выпуклых задач.
    Нижние оценки сложности методов первого порядка для решения гладких сильно выпуклых задач.}

\begin{theorem}
    Пусть задача безусловной оптимизации (32) с $L$-гладкой, $\mu$-сильно выпуклой целевой функцией $f$ решается с помощью ускоренного градиентного метода (Алгоритм 6). Тогда при $\gamma_k = \frac{1}{L}$, $\tau_k = \frac{\sqrt{L} - \sqrt{\mu}}{\sqrt{L} + \sqrt{\mu}}$ справедлива следующая оценка сходимости:
    $$f(x_K) - f(x^*) \leq \left( 1 - \sqrt{\frac{\mu}{L}} \right)^K \cdot L \|x_0 - x^*\|_2^2.$$

    Более того, чтобы добиться точности $\varepsilon$ по функции ($f(x_K) - f(x^*) \leq \varepsilon$), необходимо
    $$K = O\left( \sqrt{\frac{L}{\mu}} \log \frac{L \|x_0 - x^*\|_2^2}{\varepsilon} \right)$$
    итераций.

\end{theorem}

\begin{theorem}
    Нижняя оценка на оракульную сложность. Для любого метода из класса, описанного выше, существует безусловная задача оптимизации с $L$-гладкой, $\mu$-сильно выпуклой целевой функцией $f$, такая, что для решения этой задачи методу необходимо
    $$\Omega\left( \frac{L \| x_0 - x^* \|_2^2}{\mu \varepsilon} \log \frac{L}{\mu} \right)$$
    вызовов оракула.

\end{theorem}